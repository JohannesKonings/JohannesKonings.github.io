<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/next-blog/out/_next/static/css/66c48826d6382dcb.css" as="style" crossorigin=""/><link rel="stylesheet" href="/next-blog/out/_next/static/css/66c48826d6382dcb.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/next-blog/out/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/next-blog/out/_next/static/chunks/webpack-7af3f00e54ee1119.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/framework-5429a50ba5373c56.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/main-def68a4901fa3cc6.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/pages/_app-a5ae041df49b62a0.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/56-99b6b0e6945aba0d.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/pages/post/%5Bslug%5D-c07d00169c09ab18.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/2zVoAH4240IV3odeQrveE/_buildManifest.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/2zVoAH4240IV3odeQrveE/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><div class="flex flex-col min-h-screen"><header class="bg-fuchsia-100 mb-8 py-4"><div class="container mx-auto flex justify-center"><a href="/next-blog/out">üè°</a><span class="mx-auto">Welcome to my blog</span> </div></header><main class="container mx-auto flex-1"><div><div class="prose mx-auto"><h1>Example how to analyze DynamoDB item changes with Kinesis and Athena created with CDK</h1><div><p>This is the same like described [here]({{ site.baseurl }}/aws/2021/08/27/aws_example_ddb_analytics/), but instead of terraform it's build with <a href="https://aws.amazon.com/cdk/">CDK</a>.</p>
<p>To bootstrap the project run this command: <code>cdk init app --language typescript</code>
Further information are <a href="https://docs.aws.amazon.com/cdk/latest/guide/hello_world.html">here</a></p>
<p>All the services are in <a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-cdk/blob/main/cdk/lib/cdk-stack.ts">this</a> file.</p>
<h2>Updates</h2>
<p>2022-09-11: Add prefix for kinesis data firehose S3 destination
2022-08-13: CDK migrated to v2</p>
<h2>KMS key</h2>
<p>This creates are KMS key with an alias to encrypt the data in the created services.</p>
<pre><code class="language-typescript">const kmsKey = new kms.Key(this, 'kmsKey', {
      enableKeyRotation: true,
    })

kmsKey.addAlias(name)
</code></pre>
<h2>DynamoDb and Kinesis Data Stream</h2>
<p>This is the creation of the DynamoDb with the Kinesis Data Stream.</p>
<pre><code class="language-typescript">const stream = new kinesis.Stream(this, 'Stream', {
      streamName: `${name}-data-stream`,
      encryption: kinesis.StreamEncryption.KMS,
      encryptionKey: kmsKey,
    })

    const table = new dynamodb.Table(this, 'Table', {
      tableName: name,
      partitionKey: { name: 'pk', type: dynamodb.AttributeType.STRING },
      billingMode: dynamodb.BillingMode.PAY_PER_REQUEST,
      encryption: dynamodb.TableEncryption.CUSTOMER_MANAGED,
      encryptionKey: kmsKey,
      kinesisStream: stream,
    })
</code></pre>
<p>That adds to the DynamoDb, a Kinesis Data Stream, and connects it to the DynamoDb.</p>
<p>![kinesis data stream]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/kinesis_data_stream.png)</p>
<p>![kinesis data stream ddb]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/kinesis_data_stream_ddb.png)</p>
<h2>Kinesis Data Firehose and S3 Bucket</h2>
<p>Kinesis Data Firehose is the connection between the Kinesis Data Stream to the S3 Bucket.</p>
<p>Unfortunately, Firehose stores the JSONs without a linefeed. Therefore it's a lambda for conversion is necessary.</p>
<p>More about that is described in this <a href="https://medium.com/analytics-vidhya/append-newline-to-amazon-kinesis-firehose-json-formatted-records-with-python-f58498d0177a">post</a></p>
<p>To have the kinesis firehose data isolated under a &quot;namespace&quot; we use a prefix.</p>
<p>It looks like this.</p>
<pre><code class="language-typescript"> const firehoseBucket = new s3.Bucket(this, 'firehose-s3-bucket', {
      bucketName: `${name}-firehose-s3-bucket`,
      encryptionKey: kmsKey,
    })

const processor = new lambda.NodejsFunction(this, 'lambda-function-processor', {
  functionName: `${name}-firehose-converter`,
  timeout: cdk.Duration.minutes(2),
  bundling: {
    sourceMap: true,
  },
})

const lambdaProcessor = new LambdaFunctionProcessor(processor, {
  retries: 5,
})

const ddbChangesPrefix = 'ddb-changes';

const s3Destination = new destinations.S3Bucket(firehoseBucket, {
  encryptionKey: kmsKey,
  bufferingInterval: cdk.Duration.seconds(60),
  processor: lambdaProcessor,
  dataOutputPrefix: `${ddbChangesPrefix}/`,
})

const firehoseDeliveryStream = new firehose.DeliveryStream(this, 'Delivery Stream', {
  deliveryStreamName: `${name}-firehose`,
  sourceStream: stream,
  destinations: [s3Destination],
})
</code></pre>
<p>The delivery of the data to the S3 bucket is buffered. Here are the default values.</p>
<p>![firehose-buffer]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/firehose_buffer.png)</p>
<h2>Glue crawler</h2>
<p>Athena needs a structured table for the SQL queries. The Glue crawler creates this from the data in the S3 bucket below the configured prefix.</p>
<p>The glue crawler isn't a L2 construct yet. So it needs a L1 construct. See <a href="https://blog.phillipninan.com/a-no-nonsense-guide-to-aws-cloud-development-kit-cdk">here</a> more about L1 - L3.</p>
<p>There is already a <a href="https://github.com/aws/aws-cdk/issues/8863">github issue</a> to create a L2 construct for the glue crawler.</p>
<pre><code class="language-typescript">const getSecurityConfiguration = new iam.PolicyDocument({
      statements: [
        new iam.PolicyStatement({
          actions: ['glue:GetSecurityConfiguration'],
          resources: ['*']
        })
      ]
    })

  const roleCrawler = new iam.Role(this, 'role crawler', {
    roleName: `${name}-crawler-role`,
    assumedBy: new iam.ServicePrincipal('glue.amazonaws.com'),
    inlinePolicies: {
      GetSecurityConfiguration: getSecurityConfiguration
    }
  })

  const glueDb = new glue.Database(this, 'glue db', {
    databaseName: `${name}-db`,
  })

  const glueSecurityOptions = new glue.SecurityConfiguration(this, 'glue security options', {
    securityConfigurationName: `${name}-security-options`,
    s3Encryption: {
      mode: glue.S3EncryptionMode.KMS,
    },
  })

  const crawler = new glue.CfnCrawler(this, 'crawler', {
    name: `${name}-crawler`,
    role: roleCrawler.roleArn,
    targets: {
      s3Targets: [
        {
          path: `s3://${firehoseBucket.bucketName}/${ddbChangesPrefix}`,
        },
      ],
    },
    databaseName: glueDb.databaseName,
    crawlerSecurityConfiguration: glueSecurityOptions.securityConfigurationName,
  })

  // const glueCrawlerLogArn = `arn:aws:logs:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:log-group:/aws-glue/crawlers:log-stream:${crawler.name}`
  const glueCrawlerLogArn = `arn:aws:logs:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:log-group:/aws-glue/crawlers*` //:log-stream:${crawler.name}`

  const glueTableArn = `arn:aws:glue:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:table/${glueDb.databaseName}/*`

  const glueCrawlerArn = `arn:aws:glue:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:crawler/${crawler.name}`

  roleCrawler.addToPolicy(
    new iam.PolicyStatement({
      resources: [
        glueCrawlerLogArn,
        glueTableArn,
        glueDb.catalogArn,
        glueDb.databaseArn,
        kmsKey.keyArn,
        firehoseBucket.bucketArn,
        `${firehoseBucket.bucketArn}/*`,
        glueCrawlerArn,
      ],
      actions: ['logs:*', 'glue:*', 'kms:*', 'S3:*'],
    })
  )
</code></pre>
<p>For test purposes, it's enough to run the crawler before any analysis. Scheduling is also possible.</p>
<p>![glue-run-crawler]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/glue_run_crawler.png)</p>
<p>That creates this table, which is accessible by Athena.</p>
<p>![glue-table]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/glue_table.png)</p>
<h2>Athena</h2>
<p>For Athena it needs an S3 bucket for the query results and, for better isolation to other projects, a workgroup.</p>
<pre><code class="language-typescript">const athenaQueryResults = new s3.Bucket(this, 'query-results', {
      bucketName: `${name}-query-results`,
      encryptionKey: kmsKey,
    })

new athena.CfnWorkGroup(this, 'analytics-athena-workgroup', {
  name: `${name}-workgroup`,
  workGroupConfiguration: {
    resultConfiguration: {
      outputLocation: `s3://${athenaQueryResults.bucketName}`,
      encryptionConfiguration: {
        encryptionOption: 'SSE_KMS',
        kmsKey: kmsKey.keyArn,
      },
    },
  },
})
</code></pre>
<p>How to anylyze the data see also [here]({{ site.baseurl }}/aws/2021/08/27/aws_example_ddb_analytics/)</p>
<h2>Cost Alert üí∞</h2>
<p>‚ö†Ô∏è Don't forget to destroy after testing. Kinesis Data Streams has <a href="https://aws.amazon.com/kinesis/data-streams/pricing/">costs</a> per hour</p>
<h2>Code</h2>
<p><a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-cdk">https://github.com/JohannesKonings/test-aws-dynamodb-athena-cdk</a></p>
</div></div></div></main><footer class="bg-fuchsia-100 mt-8 py-4"><div class="container mx-auto flex justify-center"><a href="/next-blog/out/impressum">Impressum</a></div><div class="container mx-auto flex justify-center">&lt;/&gt; on <a href="https://github.com/JohannesKonings/JohannesKonings.github.io">Github</a> ¬†<i class="fa fa-github-alt"></i></div></footer></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"frontmatter":{"layout":"post","title":"Example how to analyze DynamoDB item changes with Kinesis and Athena created with CDK","date":"2021-10-26 08:15:18","published":true,"summary":"This post is how stream data changes of a DynamoDb table via Kinesis Data Stream and Kinesis Firehose to S3, and analyze the data with Athena. Build with CDK.","categories":"aws","thumbnail":"aws_kinesis","tags":["aws","aws kinesis","aws athena","aws cdk"]},"content":"\nThis is the same like described [here]({{ site.baseurl }}/aws/2021/08/27/aws_example_ddb_analytics/), but instead of terraform it's build with [CDK](https://aws.amazon.com/cdk/).\n\nTo bootstrap the project run this command: `cdk init app --language typescript`\nFurther information are [here](https://docs.aws.amazon.com/cdk/latest/guide/hello_world.html)\n\nAll the services are in [this](https://github.com/JohannesKonings/test-aws-dynamodb-athena-cdk/blob/main/cdk/lib/cdk-stack.ts) file.\n\n## Updates\n\n2022-09-11: Add prefix for kinesis data firehose S3 destination\n2022-08-13: CDK migrated to v2\n\n## KMS key\n\nThis creates are KMS key with an alias to encrypt the data in the created services.\n\n```typescript\nconst kmsKey = new kms.Key(this, 'kmsKey', {\n      enableKeyRotation: true,\n    })\n\nkmsKey.addAlias(name)\n```\n\n## DynamoDb and Kinesis Data Stream\n\nThis is the creation of the DynamoDb with the Kinesis Data Stream.\n\n```typescript\nconst stream = new kinesis.Stream(this, 'Stream', {\n      streamName: `${name}-data-stream`,\n      encryption: kinesis.StreamEncryption.KMS,\n      encryptionKey: kmsKey,\n    })\n\n    const table = new dynamodb.Table(this, 'Table', {\n      tableName: name,\n      partitionKey: { name: 'pk', type: dynamodb.AttributeType.STRING },\n      billingMode: dynamodb.BillingMode.PAY_PER_REQUEST,\n      encryption: dynamodb.TableEncryption.CUSTOMER_MANAGED,\n      encryptionKey: kmsKey,\n      kinesisStream: stream,\n    })\n```\n\nThat adds to the DynamoDb, a Kinesis Data Stream, and connects it to the DynamoDb.\n\n![kinesis data stream]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/kinesis_data_stream.png)\n\n![kinesis data stream ddb]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/kinesis_data_stream_ddb.png)\n\n## Kinesis Data Firehose and S3 Bucket\n\nKinesis Data Firehose is the connection between the Kinesis Data Stream to the S3 Bucket.\n\nUnfortunately, Firehose stores the JSONs without a linefeed. Therefore it's a lambda for conversion is necessary.\n\nMore about that is described in this [post](https://medium.com/analytics-vidhya/append-newline-to-amazon-kinesis-firehose-json-formatted-records-with-python-f58498d0177a)\n\nTo have the kinesis firehose data isolated under a \"namespace\" we use a prefix.\n\nIt looks like this.\n\n```typescript\n const firehoseBucket = new s3.Bucket(this, 'firehose-s3-bucket', {\n      bucketName: `${name}-firehose-s3-bucket`,\n      encryptionKey: kmsKey,\n    })\n\nconst processor = new lambda.NodejsFunction(this, 'lambda-function-processor', {\n  functionName: `${name}-firehose-converter`,\n  timeout: cdk.Duration.minutes(2),\n  bundling: {\n    sourceMap: true,\n  },\n})\n\nconst lambdaProcessor = new LambdaFunctionProcessor(processor, {\n  retries: 5,\n})\n\nconst ddbChangesPrefix = 'ddb-changes';\n\nconst s3Destination = new destinations.S3Bucket(firehoseBucket, {\n  encryptionKey: kmsKey,\n  bufferingInterval: cdk.Duration.seconds(60),\n  processor: lambdaProcessor,\n  dataOutputPrefix: `${ddbChangesPrefix}/`,\n})\n\nconst firehoseDeliveryStream = new firehose.DeliveryStream(this, 'Delivery Stream', {\n  deliveryStreamName: `${name}-firehose`,\n  sourceStream: stream,\n  destinations: [s3Destination],\n})\n```\n\nThe delivery of the data to the S3 bucket is buffered. Here are the default values.\n\n![firehose-buffer]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/firehose_buffer.png)\n\n## Glue crawler\n\nAthena needs a structured table for the SQL queries. The Glue crawler creates this from the data in the S3 bucket below the configured prefix.\n\nThe glue crawler isn't a L2 construct yet. So it needs a L1 construct. See [here](https://blog.phillipninan.com/a-no-nonsense-guide-to-aws-cloud-development-kit-cdk) more about L1 - L3.\n\nThere is already a [github issue](https://github.com/aws/aws-cdk/issues/8863) to create a L2 construct for the glue crawler.\n\n\n```typescript\nconst getSecurityConfiguration = new iam.PolicyDocument({\n      statements: [\n        new iam.PolicyStatement({\n          actions: ['glue:GetSecurityConfiguration'],\n          resources: ['*']\n        })\n      ]\n    })\n\n  const roleCrawler = new iam.Role(this, 'role crawler', {\n    roleName: `${name}-crawler-role`,\n    assumedBy: new iam.ServicePrincipal('glue.amazonaws.com'),\n    inlinePolicies: {\n      GetSecurityConfiguration: getSecurityConfiguration\n    }\n  })\n\n  const glueDb = new glue.Database(this, 'glue db', {\n    databaseName: `${name}-db`,\n  })\n\n  const glueSecurityOptions = new glue.SecurityConfiguration(this, 'glue security options', {\n    securityConfigurationName: `${name}-security-options`,\n    s3Encryption: {\n      mode: glue.S3EncryptionMode.KMS,\n    },\n  })\n\n  const crawler = new glue.CfnCrawler(this, 'crawler', {\n    name: `${name}-crawler`,\n    role: roleCrawler.roleArn,\n    targets: {\n      s3Targets: [\n        {\n          path: `s3://${firehoseBucket.bucketName}/${ddbChangesPrefix}`,\n        },\n      ],\n    },\n    databaseName: glueDb.databaseName,\n    crawlerSecurityConfiguration: glueSecurityOptions.securityConfigurationName,\n  })\n\n  // const glueCrawlerLogArn = `arn:aws:logs:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:log-group:/aws-glue/crawlers:log-stream:${crawler.name}`\n  const glueCrawlerLogArn = `arn:aws:logs:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:log-group:/aws-glue/crawlers*` //:log-stream:${crawler.name}`\n\n  const glueTableArn = `arn:aws:glue:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:table/${glueDb.databaseName}/*`\n\n  const glueCrawlerArn = `arn:aws:glue:${cdk.Stack.of(this).region}:${cdk.Stack.of(this).account}:crawler/${crawler.name}`\n\n  roleCrawler.addToPolicy(\n    new iam.PolicyStatement({\n      resources: [\n        glueCrawlerLogArn,\n        glueTableArn,\n        glueDb.catalogArn,\n        glueDb.databaseArn,\n        kmsKey.keyArn,\n        firehoseBucket.bucketArn,\n        `${firehoseBucket.bucketArn}/*`,\n        glueCrawlerArn,\n      ],\n      actions: ['logs:*', 'glue:*', 'kms:*', 'S3:*'],\n    })\n  )\n```\n\nFor test purposes, it's enough to run the crawler before any analysis. Scheduling is also possible.\n\n![glue-run-crawler]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/glue_run_crawler.png)\n\nThat creates this table, which is accessible by Athena.\n\n![glue-table]({{ site.baseurl }}/img/2021-10-26-aws_example_ddb_analytics_cdk/glue_table.png)\n\n## Athena\n\nFor Athena it needs an S3 bucket for the query results and, for better isolation to other projects, a workgroup.\n\n```typescript\nconst athenaQueryResults = new s3.Bucket(this, 'query-results', {\n      bucketName: `${name}-query-results`,\n      encryptionKey: kmsKey,\n    })\n\nnew athena.CfnWorkGroup(this, 'analytics-athena-workgroup', {\n  name: `${name}-workgroup`,\n  workGroupConfiguration: {\n    resultConfiguration: {\n      outputLocation: `s3://${athenaQueryResults.bucketName}`,\n      encryptionConfiguration: {\n        encryptionOption: 'SSE_KMS',\n        kmsKey: kmsKey.keyArn,\n      },\n    },\n  },\n})\n```\n\nHow to anylyze the data see also [here]({{ site.baseurl }}/aws/2021/08/27/aws_example_ddb_analytics/)\n\n## Cost Alert üí∞\n\n‚ö†Ô∏è Don't forget to destroy after testing. Kinesis Data Streams has [costs](https://aws.amazon.com/kinesis/data-streams/pricing/) per hour\n\n\n## Code\n\n[https://github.com/JohannesKonings/test-aws-dynamodb-athena-cdk](https://github.com/JohannesKonings/test-aws-dynamodb-athena-cdk)\n\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2021-10-26-aws_example_ddb_analytics_cdk"},"buildId":"2zVoAH4240IV3odeQrveE","assetPrefix":"/next-blog/out","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>