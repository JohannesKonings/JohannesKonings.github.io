<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/next-blog/out/_next/static/css/66c48826d6382dcb.css" as="style" crossorigin=""/><link rel="stylesheet" href="/next-blog/out/_next/static/css/66c48826d6382dcb.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/next-blog/out/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/next-blog/out/_next/static/chunks/webpack-7af3f00e54ee1119.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/framework-5429a50ba5373c56.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/main-def68a4901fa3cc6.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/pages/_app-a5ae041df49b62a0.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/56-99b6b0e6945aba0d.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/chunks/pages/post/%5Bslug%5D-c07d00169c09ab18.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/2zVoAH4240IV3odeQrveE/_buildManifest.js" defer="" crossorigin=""></script><script src="/next-blog/out/_next/static/2zVoAH4240IV3odeQrveE/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><div class="flex flex-col min-h-screen"><header class="bg-fuchsia-100 mb-8 py-4"><div class="container mx-auto flex justify-center"><a href="/next-blog/out">üè°</a><span class="mx-auto">Welcome to my blog</span> </div></header><main class="container mx-auto flex-1"><div><div class="prose mx-auto"><h1>Example how to analyze DynamoDB item changes with Kinesis and Athena created with Terraform</h1><div><h1>Why?</h1>
<p>The data of a DynamoDb table is not so easy to analyze as a <a href="https://aws.amazon.com/rds/">RDS</a> with e.g., the <a href="https://www.pgadmin.org/">pgAdmin</a>.
It will be somehow possible with scan operation but it's in the most cases <a href="https://dynobase.dev/dynamodb-scan/">not recommented</a>.</p>
<p>Another possibility is the <a href="https://aws.amazon.com/blogs/aws/new-export-amazon-dynamodb-table-data-to-data-lake-amazon-s3/">export to S3 functionylity</a>.</p>
<p>In this post, it's described to use streams. Since 11/2020, it is also possible <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/now-you-can-use-amazon-kinesis-data-streams-to-capture-item-level-changes-in-your-amazon-dynamodb-table/">to use kinesis data streams</a> for such a case.</p>
<p>That also allows to analyze changes and use it for audits.</p>
<p>A example with DynamoDb streams are here:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=7QFUEh-FYYE">https://www.youtube.com/watch?v=7QFUEh-FYYE</a></li>
<li><a href="https://www.youtube.com/watch?v=17AmrTqn0GY">https://www.youtube.com/watch?v=17AmrTqn0GY</a></li>
</ul>
<h1>Architecture</h1>
<p><img src="https://raw.githubusercontent.com/JohannesKonings/test-aws-dynamodb-athena-tf/main/diagrams/overview.png" alt="architecture"></p>
<p>The lambda is sending fake person data to DynamoDb. The integration of the Kinesis Data Stream into the DynamoDb is connected to the Kinesis Firehose, which sends the changes partitioned to the S3 bucket.</p>
<p>The Glue crawler will recognize the data structure and create a table, which can be accessed from Athena to analyze the data.</p>
<p>Let's see the certain building blocks</p>
<h1>Lambda (for data creation)</h1>
<p>The <a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/lambda.tf">Lambda</a> is created with a module from <a href="serverless.tf">serverless.tf</a>.</p>
<p>The source code is <a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/src/persons-loader/index.js">here</a></p>
<p>The number of created persons depends on the test event.</p>
<pre><code class="language-json">{
  &quot;batchSize&quot;: 5
}
</code></pre>
<h1>DynamoDb and Kinesis Data Stream</h1>
<p><a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/dynamodb.tf">This</a> is the creation of the DynamoDb with the Kinesis Data Stream.</p>
<pre><code class="language-terraform">resource &quot;aws_dynamodb_table&quot; &quot;aws_dynamodb_table&quot; {
  name         = var.TABLE_NAME
  billing_mode = &quot;PAY_PER_REQUEST&quot;
  hash_key     = &quot;pk&quot;

  attribute {
    name = &quot;pk&quot;
    type = &quot;S&quot;
  }
}

resource &quot;aws_kinesis_stream&quot; &quot;aws_kinesis_stream&quot; {
  name            = &quot;${var.TABLE_NAME}-data-stream&quot;
  shard_count     = 1
  encryption_type = &quot;KMS&quot;
  kms_key_id      = aws_kms_key.aws_kms_key.arn
}

resource &quot;aws_dynamodb_kinesis_streaming_destination&quot; &quot;aws_dynamodb_kinesis_streaming_destination&quot; {
  stream_arn = aws_kinesis_stream.aws_kinesis_stream.arn
  table_name = aws_dynamodb_table.aws_dynamodb_table.name
}
</code></pre>
<p>That adds to the DynamoDb, a Kinesis Data Stream, and connects it to the DynamoDb.</p>
<p>![kinesis data stream]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/kinesis_data_stream.png)</p>
<p>![kinesis data stream ddb]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/kinesis_data_stream_ddb.png)</p>
<h1>Kinesis Data Firehose and S3 Bucket</h1>
<p>Kinesis Data Firehose is the connection between the Kinesis Data Stream to the S3 Bucket.</p>
<p>Unfortunately, Firehose stores the JSONs without a linefeed. Therefore it's a lambda for conversion is necessary.</p>
<p>More about that is described in this <a href="https://medium.com/analytics-vidhya/append-newline-to-amazon-kinesis-firehose-json-formatted-records-with-python-f58498d0177a">post</a></p>
<p>Besides policy configuration, it looks like this.</p>
<pre><code class="language-terraform">resource &quot;aws_kinesis_firehose_delivery_stream&quot; &quot;aws_kinesis_firehose_delivery_stream&quot; {
  name        = local.firehose-name
  destination = &quot;extended_s3&quot;

  kinesis_source_configuration {
    kinesis_stream_arn = aws_kinesis_stream.aws_kinesis_stream.arn
    role_arn           = aws_iam_role.aws_iam_role.arn
  }

  extended_s3_configuration {
    role_arn   = aws_iam_role.aws_iam_role.arn
    bucket_arn = aws_s3_bucket.aws_s3_bucket.arn

    processing_configuration {
      enabled = &quot;true&quot;

      processors {
        type = &quot;Lambda&quot;

        parameters {
          parameter_name  = &quot;LambdaArn&quot;
          parameter_value = &quot;${module.lambda_function_persons_firehose_converter.lambda_function_arn}:$LATEST&quot;
        }
      }
    }

    cloudwatch_logging_options {
      enabled         = true
      log_group_name  = aws_cloudwatch_log_group.aws_cloudwatch_log_group_firehose.name
      log_stream_name = aws_cloudwatch_log_stream.aws_cloudwatch_log_stream_firehose.name
    }
  }
}
</code></pre>
<p>Details are <a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/kinesis_firehose.tf">here</a></p>
<p>The delivery of the data to the S3 bucket is buffered. Here are the default values.</p>
<p>![firehose-buffer]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/firehose_buffer.png)</p>
<h1>Glue crawler</h1>
<p>Athena needs a structured table for the SQL queries. The Glue crawler creates this from the data in the S3 bucket.</p>
<pre><code class="language-terraform">resource &quot;aws_glue_crawler&quot; &quot;aws_glue_crawler&quot; {
  database_name = aws_glue_catalog_database.aws_glue_bookings_database.name
  name          = local.glue-crawler-name
  role          = aws_iam_role.aws_iam_role_glue_crawler.arn

  configuration = jsonencode(
    {
      &quot;Version&quot; : 1.0
      CrawlerOutput = {
        Partitions = { AddOrUpdateBehavior = &quot;InheritFromTable&quot; }
      }
    }
  )

  s3_target {
    path = &quot;s3://${aws_s3_bucket.aws_s3_bucket.bucket}&quot;
  }
}
</code></pre>
<p>Details <a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/glue.tf">here</a></p>
<p>For test purposes, it's enough to run the crawler before any analysis. Scheduling is also possible.</p>
<p>![glue-run-crawler]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/glue_run_crawler.png)</p>
<p>That creates this table, which is accessible by Athena.</p>
<p>![glue-table]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/glue_table.png)</p>
<h1>Athena</h1>
<p>For Athena it needs an S3 bucket for the query results and, for better isolation to other projects, a workgroup.</p>
<pre><code class="language-terraform">locals {
  athena-query-results-s3-name = &quot;${var.TABLE_NAME}-query-results&quot;
  athena-workgroup-name        = &quot;${var.TABLE_NAME}-workgroup&quot;
}
resource &quot;aws_s3_bucket&quot; &quot;aws_s3_bucket_bookings_query_results&quot; {
  bucket = local.athena-query-results-s3-name
  acl    = &quot;private&quot;

  versioning {
    enabled = true
  }

  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        kms_master_key_id = aws_kms_key.aws_kms_key.arn
        sse_algorithm     = &quot;aws:kms&quot;
      }
    }
  }
}

resource &quot;aws_athena_workgroup&quot; &quot;aws_athena_workgroup&quot; {
  name = local.athena-workgroup-name

  configuration {
    enforce_workgroup_configuration    = true
    publish_cloudwatch_metrics_enabled = true

    result_configuration {
      output_location = &quot;s3://${aws_s3_bucket.aws_s3_bucket_bookings_query_results.bucket}/output/&quot;

      encryption_configuration {
        encryption_option = &quot;SSE_KMS&quot;
        kms_key_arn       = aws_kms_key.aws_kms_key.arn
      }
    }
  }
}
</code></pre>
<p>Details <a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/glue.tf">here</a></p>
<h2>Analysis</h2>
<p>First select the new workgroup.</p>
<p>![athena-workgroup]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/athena_workgroup.png)</p>
<p>And than the new Database.</p>
<p>![athena-database]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/athena_database.png)</p>
<h3>Query example</h3>
<p>DynamoDb sends the changes of an item as INSERT, MODIFY or REMOVE. To the current data of the table, this Query will work.</p>
<pre><code class="language-SQL">SELECT dynamodb.newimage.pk.s AS pk,
         dynamodb.newimage.person.M.firstname.s AS firstname,
         dynamodb.newimage.person.M.lastname.s AS lastname,
         dynamodb.approximatecreationdatetime AS ts,
         dynamodb.newimage,
         *
FROM &quot;persons-db&quot;.&quot;persons_firehose_s3_bucket&quot; AS persons1
WHERE (eventname = 'INSERT'
        OR eventname = 'MODIFY')
        AND dynamodb.approximatecreationdatetime =
    (SELECT MAX(dynamodb.approximatecreationdatetime)
    FROM &quot;persons-db&quot;.&quot;persons_firehose_s3_bucket&quot; AS persons2
    WHERE persons2.dynamodb.newimage.pk.s = persons1.dynamodb.newimage.pk.s);
</code></pre>
<p>![athena-ddb]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/athena_ddb.png)</p>
<h1>Cost Alert üí∞</h1>
<p>‚ö†Ô∏è Don't forget to destroy after testing. Kinesis Data Streams has <a href="https://aws.amazon.com/kinesis/data-streams/pricing/">costs</a> per hour</p>
<h1>Code</h1>
<p><a href="https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf">https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf</a></p>
</div></div></div></main><footer class="bg-fuchsia-100 mt-8 py-4"><div class="container mx-auto flex justify-center"><a href="/next-blog/out/impressum">Impressum</a></div><div class="container mx-auto flex justify-center">&lt;/&gt; on <a href="https://github.com/JohannesKonings/JohannesKonings.github.io">Github</a> ¬†<i class="fa fa-github-alt"></i></div></footer></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"frontmatter":{"layout":"post","title":"Example how to analyze DynamoDB item changes with Kinesis and Athena created with Terraform","date":"2021-08-27 08:15:18","published":true,"summary":"This post is how stream data changes of a DynamoDb table via Kinesis Data Stream and Kinesis Firehose to S3, and analyze the data with Athena","categories":"aws","thumbnail":"aws_kinesis","tags":["aws","aws kinesis","aws athena","terraform"]},"content":"\n# Why?\n\nThe data of a DynamoDb table is not so easy to analyze as a [RDS](https://aws.amazon.com/rds/) with e.g., the [pgAdmin](https://www.pgadmin.org/).\nIt will be somehow possible with scan operation but it's in the most cases [not recommented](https://dynobase.dev/dynamodb-scan/).\n\nAnother possibility is the [export to S3 functionylity](https://aws.amazon.com/blogs/aws/new-export-amazon-dynamodb-table-data-to-data-lake-amazon-s3/).\n\nIn this post, it's described to use streams. Since 11/2020, it is also possible [to use kinesis data streams](https://aws.amazon.com/about-aws/whats-new/2020/11/now-you-can-use-amazon-kinesis-data-streams-to-capture-item-level-changes-in-your-amazon-dynamodb-table/) for such a case.\n\nThat also allows to analyze changes and use it for audits.\n\nA example with DynamoDb streams are here:\n- [https://www.youtube.com/watch?v=7QFUEh-FYYE](https://www.youtube.com/watch?v=7QFUEh-FYYE)\n- [https://www.youtube.com/watch?v=17AmrTqn0GY](https://www.youtube.com/watch?v=17AmrTqn0GY)\n\n\n# Architecture\n\n![architecture](https://raw.githubusercontent.com/JohannesKonings/test-aws-dynamodb-athena-tf/main/diagrams/overview.png)\n\nThe lambda is sending fake person data to DynamoDb. The integration of the Kinesis Data Stream into the DynamoDb is connected to the Kinesis Firehose, which sends the changes partitioned to the S3 bucket.\n\nThe Glue crawler will recognize the data structure and create a table, which can be accessed from Athena to analyze the data.\n\nLet's see the certain building blocks\n\n# Lambda (for data creation)\n\nThe [Lambda](https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/lambda.tf) is created with a module from [serverless.tf](serverless.tf).\n\nThe source code is [here](https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/src/persons-loader/index.js)\n\nThe number of created persons depends on the test event.\n\n```json\n{\n  \"batchSize\": 5\n}\n```\n\n# DynamoDb and Kinesis Data Stream\n\n[This](https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/dynamodb.tf) is the creation of the DynamoDb with the Kinesis Data Stream.\n\n```terraform\nresource \"aws_dynamodb_table\" \"aws_dynamodb_table\" {\n  name         = var.TABLE_NAME\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"pk\"\n\n  attribute {\n    name = \"pk\"\n    type = \"S\"\n  }\n}\n\nresource \"aws_kinesis_stream\" \"aws_kinesis_stream\" {\n  name            = \"${var.TABLE_NAME}-data-stream\"\n  shard_count     = 1\n  encryption_type = \"KMS\"\n  kms_key_id      = aws_kms_key.aws_kms_key.arn\n}\n\nresource \"aws_dynamodb_kinesis_streaming_destination\" \"aws_dynamodb_kinesis_streaming_destination\" {\n  stream_arn = aws_kinesis_stream.aws_kinesis_stream.arn\n  table_name = aws_dynamodb_table.aws_dynamodb_table.name\n}\n```\n\nThat adds to the DynamoDb, a Kinesis Data Stream, and connects it to the DynamoDb.\n\n![kinesis data stream]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/kinesis_data_stream.png)\n\n![kinesis data stream ddb]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/kinesis_data_stream_ddb.png)\n\n# Kinesis Data Firehose and S3 Bucket\n\nKinesis Data Firehose is the connection between the Kinesis Data Stream to the S3 Bucket.\n\nUnfortunately, Firehose stores the JSONs without a linefeed. Therefore it's a lambda for conversion is necessary.\n\nMore about that is described in this [post](https://medium.com/analytics-vidhya/append-newline-to-amazon-kinesis-firehose-json-formatted-records-with-python-f58498d0177a)\n\nBesides policy configuration, it looks like this.\n\n```terraform\nresource \"aws_kinesis_firehose_delivery_stream\" \"aws_kinesis_firehose_delivery_stream\" {\n  name        = local.firehose-name\n  destination = \"extended_s3\"\n\n  kinesis_source_configuration {\n    kinesis_stream_arn = aws_kinesis_stream.aws_kinesis_stream.arn\n    role_arn           = aws_iam_role.aws_iam_role.arn\n  }\n\n  extended_s3_configuration {\n    role_arn   = aws_iam_role.aws_iam_role.arn\n    bucket_arn = aws_s3_bucket.aws_s3_bucket.arn\n\n    processing_configuration {\n      enabled = \"true\"\n\n      processors {\n        type = \"Lambda\"\n\n        parameters {\n          parameter_name  = \"LambdaArn\"\n          parameter_value = \"${module.lambda_function_persons_firehose_converter.lambda_function_arn}:$LATEST\"\n        }\n      }\n    }\n\n    cloudwatch_logging_options {\n      enabled         = true\n      log_group_name  = aws_cloudwatch_log_group.aws_cloudwatch_log_group_firehose.name\n      log_stream_name = aws_cloudwatch_log_stream.aws_cloudwatch_log_stream_firehose.name\n    }\n  }\n}\n```\nDetails are [here](https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/kinesis_firehose.tf)\n\nThe delivery of the data to the S3 bucket is buffered. Here are the default values.\n\n![firehose-buffer]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/firehose_buffer.png)\n\n# Glue crawler\n\nAthena needs a structured table for the SQL queries. The Glue crawler creates this from the data in the S3 bucket.\n\n```terraform\nresource \"aws_glue_crawler\" \"aws_glue_crawler\" {\n  database_name = aws_glue_catalog_database.aws_glue_bookings_database.name\n  name          = local.glue-crawler-name\n  role          = aws_iam_role.aws_iam_role_glue_crawler.arn\n\n  configuration = jsonencode(\n    {\n      \"Version\" : 1.0\n      CrawlerOutput = {\n        Partitions = { AddOrUpdateBehavior = \"InheritFromTable\" }\n      }\n    }\n  )\n\n  s3_target {\n    path = \"s3://${aws_s3_bucket.aws_s3_bucket.bucket}\"\n  }\n}\n```\n\nDetails [here](https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/glue.tf)\n\nFor test purposes, it's enough to run the crawler before any analysis. Scheduling is also possible.\n\n![glue-run-crawler]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/glue_run_crawler.png)\n\nThat creates this table, which is accessible by Athena.\n\n![glue-table]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/glue_table.png)\n\n# Athena\n\nFor Athena it needs an S3 bucket for the query results and, for better isolation to other projects, a workgroup.\n\n```terraform\nlocals {\n  athena-query-results-s3-name = \"${var.TABLE_NAME}-query-results\"\n  athena-workgroup-name        = \"${var.TABLE_NAME}-workgroup\"\n}\nresource \"aws_s3_bucket\" \"aws_s3_bucket_bookings_query_results\" {\n  bucket = local.athena-query-results-s3-name\n  acl    = \"private\"\n\n  versioning {\n    enabled = true\n  }\n\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        kms_master_key_id = aws_kms_key.aws_kms_key.arn\n        sse_algorithm     = \"aws:kms\"\n      }\n    }\n  }\n}\n\nresource \"aws_athena_workgroup\" \"aws_athena_workgroup\" {\n  name = local.athena-workgroup-name\n\n  configuration {\n    enforce_workgroup_configuration    = true\n    publish_cloudwatch_metrics_enabled = true\n\n    result_configuration {\n      output_location = \"s3://${aws_s3_bucket.aws_s3_bucket_bookings_query_results.bucket}/output/\"\n\n      encryption_configuration {\n        encryption_option = \"SSE_KMS\"\n        kms_key_arn       = aws_kms_key.aws_kms_key.arn\n      }\n    }\n  }\n}\n```\nDetails [here](https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf/blob/main/terraform/glue.tf)\n\n## Analysis\n\nFirst select the new workgroup.\n\n![athena-workgroup]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/athena_workgroup.png)\n\nAnd than the new Database.\n\n![athena-database]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/athena_database.png)\n\n\n### Query example\n\nDynamoDb sends the changes of an item as INSERT, MODIFY or REMOVE. To the current data of the table, this Query will work.\n\n```SQL\nSELECT dynamodb.newimage.pk.s AS pk,\n         dynamodb.newimage.person.M.firstname.s AS firstname,\n         dynamodb.newimage.person.M.lastname.s AS lastname,\n         dynamodb.approximatecreationdatetime AS ts,\n         dynamodb.newimage,\n         *\nFROM \"persons-db\".\"persons_firehose_s3_bucket\" AS persons1\nWHERE (eventname = 'INSERT'\n        OR eventname = 'MODIFY')\n        AND dynamodb.approximatecreationdatetime =\n    (SELECT MAX(dynamodb.approximatecreationdatetime)\n    FROM \"persons-db\".\"persons_firehose_s3_bucket\" AS persons2\n    WHERE persons2.dynamodb.newimage.pk.s = persons1.dynamodb.newimage.pk.s);\n```\n\n![athena-ddb]({{ site.baseurl }}/img/2021-08-27-aws_example_ddb_analytics/athena_ddb.png)\n\n# Cost Alert üí∞\n\n‚ö†Ô∏è Don't forget to destroy after testing. Kinesis Data Streams has [costs](https://aws.amazon.com/kinesis/data-streams/pricing/) per hour\n\n\n# Code\n\n[https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf](https://github.com/JohannesKonings/test-aws-dynamodb-athena-tf)\n\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2021-08-27-aws_example_ddb_analytics"},"buildId":"2zVoAH4240IV3odeQrveE","assetPrefix":"/next-blog/out","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>